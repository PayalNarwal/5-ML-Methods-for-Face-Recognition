{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m234s\u001b[0m 4s/step - accuracy: 0.3684 - loss: 1.4884 - val_accuracy: 0.4437 - val_loss: 1.8650\n",
      "Epoch 2/5\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 4s/step - accuracy: 0.2067 - loss: 0.2304 - val_accuracy: 0.1312 - val_loss: 0.0988\n",
      "Epoch 3/5\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m253s\u001b[0m 4s/step - accuracy: 0.1676 - loss: 0.1365 - val_accuracy: 0.1375 - val_loss: 0.0992\n",
      "Epoch 4/5\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 5s/step - accuracy: 0.1489 - loss: 0.1022 - val_accuracy: 0.1813 - val_loss: 0.1381\n",
      "Epoch 5/5\n",
      "\u001b[1m60/60\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 4s/step - accuracy: 0.2039 - loss: 0.2155 - val_accuracy: 0.2188 - val_loss: 0.1366\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 3s/step\n",
      "Test Accuracy: 0.79\n",
      "Test Precision: 0.82\n",
      "Test Recall: 0.74\n",
      "Test F1 Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load and preprocess the images\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        for filename in os.listdir(label_folder):\n",
    "            img_path = os.path.join(label_folder, filename)\n",
    "            image = img_to_array(load_img(img_path, target_size=(128, 128))) / 255.0\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Create pairs\n",
    "def make_pairs(images, labels):\n",
    "    pairs = []\n",
    "    labels_pair = []\n",
    "    num_classes = len(np.unique(labels))\n",
    "    digit_indices = [np.where(labels == label)[0] for label in np.unique(labels)]\n",
    "\n",
    "    for idx1 in range(len(images)):\n",
    "        label = labels[idx1]\n",
    "        same_class_indices = digit_indices[np.where(np.unique(labels) == label)[0][0]]\n",
    "        idx2 = np.random.choice(same_class_indices)\n",
    "        pairs.append([images[idx1], images[idx2]])\n",
    "        labels_pair.append(1)\n",
    "\n",
    "        diff_class_indices = np.concatenate([digit_indices[i] for i in range(num_classes) if i != np.where(np.unique(labels) == label)[0][0]])\n",
    "        idx2 = np.random.choice(diff_class_indices)\n",
    "        pairs.append([images[idx1], images[idx2]])\n",
    "        labels_pair.append(0)\n",
    "\n",
    "    return np.array(pairs), np.array(labels_pair)\n",
    "\n",
    "# Load dataset\n",
    "folder_path = \"./converted_images\"  # Update with your dataset path\n",
    "images, labels = load_images_from_folder(folder_path)\n",
    "\n",
    "# Create pairs\n",
    "pairs, labels_pair = make_pairs(images, labels)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "pairs_train, pairs_temp, labels_train, labels_temp = train_test_split(pairs, labels_pair, test_size=0.4, random_state=42)\n",
    "pairs_val, pairs_test, labels_val, labels_test = train_test_split(pairs_temp, labels_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the Siamese network\n",
    "def build_base_network(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)  # Reduced from 4096 to 1024\n",
    "    return Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "input_shape = (128, 128, 3)  # Reduced image size\n",
    "base_network = build_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "model.compile(loss=contrastive_loss, optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train, \n",
    "                    validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val),\n",
    "                    batch_size=8,  # Reduced batch size\n",
    "                    epochs=5)  # Reduced epochs\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict([pairs_test[:, 0], pairs_test[:, 1]])\n",
    "\n",
    "# Convert distances to binary predictions\n",
    "y_pred_binary = np.where(y_pred < 0.5, 1, 0)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(labels_test, y_pred_binary)\n",
    "test_precision = precision_score(labels_test, y_pred_binary)\n",
    "test_recall = recall_score(labels_test, y_pred_binary)\n",
    "test_f1 = f1_score(labels_test, y_pred_binary)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test Precision: {test_precision:.2f}\")\n",
    "print(f\"Test Recall: {test_recall:.2f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpuNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in c:\\users\\rahla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\rahla\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from faiss-cpu) (23.2)\n",
      "Downloading faiss_cpu-1.8.0.post1-cp312-cp312-win_amd64.whl (14.6 MB)\n",
      "   ---------------------------------------- 0.0/14.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/14.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.0/14.6 MB 3.1 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 2.1/14.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.4/14.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 4.7/14.6 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.8/14.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.1/14.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.1/14.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.4/14.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.5/14.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.3/14.6 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.1/14.6 MB 5.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.2/14.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.6/14.6 MB 5.0 MB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.8.0.post1\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 2s/step - accuracy: 0.0506 - loss: 54.4157 - val_accuracy: 0.1250 - val_loss: 0.0838\n",
      "Epoch 2/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 2s/step - accuracy: 0.1124 - loss: 0.6726 - val_accuracy: 0.0240 - val_loss: 2.9481\n",
      "Epoch 3/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 2s/step - accuracy: 0.1097 - loss: 0.9275 - val_accuracy: 0.0440 - val_loss: 0.6103\n",
      "Epoch 4/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 2s/step - accuracy: 0.1804 - loss: 3.7498 - val_accuracy: 0.9390 - val_loss: 0.6724\n",
      "Epoch 5/5\n",
      "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 2s/step - accuracy: 0.8594 - loss: 1.5894 - val_accuracy: 0.9760 - val_loss: 0.9754\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 217ms/step\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 188ms/step\n",
      "Test Accuracy: 0.98\n",
      "Test Precision: 0.96\n",
      "Test Recall: 0.98\n",
      "Test F1 Score: 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import faiss\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess the images with reduced resolution\n",
    "def load_images_from_folder(folder, target_size=(64, 64)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for label in os.listdir(folder):\n",
    "        label_folder = os.path.join(folder, label)\n",
    "        for filename in os.listdir(label_folder):\n",
    "            img_path = os.path.join(label_folder, filename)\n",
    "            image = img_to_array(load_img(img_path, target_size=target_size)) / 255.0\n",
    "            images.append(image)\n",
    "            labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "# Build the Siamese network\n",
    "def build_base_network(input_shape):\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = base_model.output\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='relu')(x)  # Reduced dense layer size\n",
    "    return Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    margin = 1\n",
    "    return K.mean(y_true * K.square(y_pred) + (1 - y_true) * K.square(K.maximum(margin - y_pred, 0)))\n",
    "\n",
    "# Load dataset with reduced image size\n",
    "folder_path = \"./converted_images\"  # Update with your dataset path\n",
    "images, labels = load_images_from_folder(folder_path, target_size=(64, 64))\n",
    "\n",
    "# Convert string labels to numeric labels\n",
    "unique_labels = np.unique(labels)\n",
    "label_to_index = {label: index for index, label in enumerate(unique_labels)}\n",
    "labels_numeric = np.array([label_to_index[label] for label in labels])\n",
    "\n",
    "# Create pairs of images and labels (limited number of pairs)\n",
    "def create_pairs(images, labels, num_pairs=5000):\n",
    "    num_images = len(images)\n",
    "    num_classes = len(np.unique(labels))\n",
    "    pairs = []\n",
    "    labels_pair = []\n",
    "    \n",
    "    for _ in range(num_pairs):\n",
    "        # Randomly select two images\n",
    "        idx1, idx2 = np.random.choice(num_images, 2, replace=False)\n",
    "        img1, img2 = images[idx1], images[idx2]\n",
    "        lbl1, lbl2 = labels[idx1], labels[idx2]\n",
    "        \n",
    "        pairs.append((img1, img2))\n",
    "        labels_pair.append(1 if lbl1 == lbl2 else 0)\n",
    "    \n",
    "    return np.array(pairs), np.array(labels_pair)\n",
    "\n",
    "# Create pairs and labels for training\n",
    "pairs, labels_pair = create_pairs(images, labels_numeric)\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "pairs_train, pairs_temp, labels_train, labels_temp = train_test_split(pairs, labels_pair, test_size=0.4, random_state=42)\n",
    "pairs_val, pairs_test, labels_val, labels_test = train_test_split(pairs_temp, labels_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "input_shape = (64, 64, 3)  # Adjusted to match image size\n",
    "base_network = build_base_network(input_shape)\n",
    "\n",
    "input_a = Input(shape=input_shape)\n",
    "input_b = Input(shape=input_shape)\n",
    "\n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)\n",
    "\n",
    "distance = Lambda(euclidean_distance)([processed_a, processed_b])\n",
    "\n",
    "model = Model([input_a, input_b], distance)\n",
    "model.compile(loss=contrastive_loss, optimizer=Adam(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 16\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit([pairs_train[:, 0], pairs_train[:, 1]], labels_train.astype(np.float32), \n",
    "                    validation_data=([pairs_val[:, 0], pairs_val[:, 1]], labels_val.astype(np.float32)),\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs)\n",
    "\n",
    "# Extract features for the dataset\n",
    "def extract_features(images, model):\n",
    "    return model.predict(images, batch_size=batch_size)\n",
    "\n",
    "# Predict labels for test dataset\n",
    "def predict_labels(test_images, database_images, database_labels, model):\n",
    "    test_features = extract_features(test_images, model)\n",
    "    database_features = extract_features(database_images, model)\n",
    "    \n",
    "    # Build the FAISS index\n",
    "    d = test_features.shape[1]\n",
    "    index = faiss.IndexFlatL2(d)\n",
    "    index.add(database_features)\n",
    "    \n",
    "    # Search for nearest neighbors\n",
    "    _, indices = index.search(test_features, 1)\n",
    "    predicted_labels = [database_labels[i[0]] for i in indices]\n",
    "\n",
    "    return np.array(predicted_labels)\n",
    "\n",
    "# Create a database of images for label prediction\n",
    "database_images = images\n",
    "database_labels = labels_numeric\n",
    "\n",
    "# Predict labels for the test dataset images\n",
    "predicted_labels = predict_labels(pairs_test[:, 0], database_images, database_labels, base_network)\n",
    "\n",
    "# Convert numeric labels back to original string labels\n",
    "index_to_label = {index: label for label, index in label_to_index.items()}\n",
    "labels_test_str = [index_to_label[label] for label in labels_test]\n",
    "predicted_labels_str = [index_to_label[label] for label in predicted_labels]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "test_accuracy = accuracy_score(labels_test_str, predicted_labels_str)\n",
    "test_precision = precision_score(labels_test_str, predicted_labels_str, average='weighted')\n",
    "test_recall = recall_score(labels_test_str, predicted_labels_str, average='weighted')\n",
    "test_f1 = f1_score(labels_test_str, predicted_labels_str, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "print(f\"Test Precision: {test_precision:.2f}\")\n",
    "print(f\"Test Recall: {test_recall:.2f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
